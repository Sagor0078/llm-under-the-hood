- I will add LLM inference techniques such as Distillation, Batching, Model Parallelism/Sharding, Model Compilation and Graph Optimization, and Speculative (Assisted) Decoding in the future